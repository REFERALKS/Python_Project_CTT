from __future__ import annotations

import base64
import io
import json
import logging
import os
import tempfile
import threading
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Union

import telebot
from telebot import types
from openai import OpenAI

try:
    from tiktoken import get_encoding  # type: ignore
except Exception:  # pragma: no cover
    get_encoding = None  # type: ignore


# -------------------- CONFIG --------------------

# SECURITY: –Ω–µ —Ö–∞—Ä–¥–∫–æ–¥—å —Ç–æ–∫–µ–Ω –≤ –∫–æ–¥–µ. –¢–≤–æ–π —Ç–æ–∫–µ–Ω –±—ã–ª –∑–∞—Å–≤–µ—á–µ–Ω ‚Äî –µ–≥–æ –Ω—É–∂–Ω–æ –æ—Ç–æ–∑–≤–∞—Ç—å —É @BotFather –∏ –≤—ã–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤—ã–π.
API_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "8057312342:AAEpPXaXZdgWyfTOK3IAeTIChDNZy6pUKP0").strip()
if not API_TOKEN:
    raise RuntimeError(
        "TELEGRAM_BOT_TOKEN is not set. "
        "Set it in env vars. (Also rotate the leaked token if it was exposed.)"
    )

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:1234/v1").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "lm-studio").strip()

HISTORY_FILE = os.getenv("HISTORY_FILE", "history.json").strip()
SETTINGS_FILE = os.getenv("SETTINGS_FILE", "settings.json").strip()

TOKEN_LIMIT = int(os.getenv("TOKEN_LIMIT", "16834"))

AVAILABLE_MODELS = {
    "ministral": "mistralai/ministral-3-14b-reasoning",
    "qwen_vl": "qwen/qwen3-vl-30b",
    "local_default": "local-model",
}

ROLES = {
    "default": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.",
    "coder": "–¢—ã senior python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –î–∞–≤–∞–π –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è.",
    "translator": "–¢—ã –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–æ—á–Ω–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ.",
    "physicist": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä —Ñ–∏–∑–∏–∫–∏. –û–±—ä—è—Å–Ω—è–π —Å—Ç—Ä–æ–≥–æ, –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ.",
    "creative": "–¢—ã –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ø–∏—Å–∞—Ç–µ–ª—å. –ü–∏—à–∏ –æ–±—Ä–∞–∑–Ω–æ, –Ω–æ –ø–æ –∑–∞–¥–∞—á–µ.",
}

# –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Ç–≤–æ–∏–º –ø–∞—Ä—Å–µ—Ä–æ–º "–û–¢–í–ï–¢:"
RESPONSE_FORMAT_INSTRUCTION = (
    "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
    "–û–¢–í–ï–¢: <—Ç–≤–æ–π –æ—Ç–≤–µ—Ç>\n"
    "–ù–µ –¥–æ–±–∞–≤–ª—è–π –¥—Ä—É–≥–∏–µ —Å–µ–∫—Ü–∏–∏."
)

# –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—É —Ä–∞–∑–Ω—ã—Ö VLM –º–æ–¥–µ–ª–µ–π –ø–æ-—Ä–∞–∑–Ω–æ–º—É, —ç—Ç–æ heuristic)
IMAGE_TOKEN_ESTIMATE = int(os.getenv("IMAGE_TOKEN_ESTIMATE", "900"))

# Chat overhead heuristic (–ø—Ä–∏–º–µ—Ä–Ω–æ)
TOKENS_PER_MESSAGE_OVERHEAD = 3
TOKENS_PRIMING_OVERHEAD = 3

# –ò—Å—Ç–æ—Ä–∏—è: –µ—Å–ª–∏ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ, –æ–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –¥–æ —ç—Ç–æ–≥–æ –ª–∏–º–∏—Ç–∞
MIN_TEXT_TOKENS_TO_KEEP = int(os.getenv("MIN_TEXT_TOKENS_TO_KEEP", "256"))

# –†–æ—Ç–∞—Ü–∏—è history.json –ø–æ —Ä–∞–∑–º–µ—Ä—É
HISTORY_ROTATE_MAX_BYTES = int(os.getenv("HISTORY_ROTATE_MAX_BYTES", str(5 * 1024 * 1024)))  # 5 MB
HISTORY_ROTATE_BACKUPS = int(os.getenv("HISTORY_ROTATE_BACKUPS", "3"))


# -------------------- LOGGING --------------------

logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")
logger = logging.getLogger("tg-bot")


# -------------------- LOW-LEVEL UTIL --------------------

def uid(user_id: Union[int, str]) -> str:
    """–°—Ç–∞–±–∏–ª—å–Ω—ã–π –∫–ª—é—á –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è JSON."""
    return str(user_id)


def atomic_write_json(path: str, data: Any) -> None:
    """–ê—Ç–æ–º–∞—Ä–Ω–∞—è –∑–∞–ø–∏—Å—å JSON: –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –±–∏—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏ –ø–∞–¥–µ–Ω–∏–∏."""
    directory = os.path.dirname(os.path.abspath(path)) or "."
    os.makedirs(directory, exist_ok=True)

    fd, tmp_path = tempfile.mkstemp(prefix=".tmp_", suffix=".json", dir=directory)
    try:
        with os.fdopen(fd, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
            f.flush()
            os.fsync(f.fileno())
        os.replace(tmp_path, path)
    finally:
        try:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        except Exception:
            pass


def rotate_file(path: str, max_bytes: int, backups: int) -> None:
    """
    –ï—Å–ª–∏ —Ñ–∞–π–ª path >= max_bytes, –¥–µ–ª–∞–µ–º —Ä–æ—Ç–∞—Ü–∏—é:
      path.(backups) —É–¥–∞–ª—è–µ–º,
      path.(i-1) -> path.i,
      path -> path.1
    """
    if backups <= 0:
        return
    try:
        if not os.path.exists(path):
            return
        size = os.path.getsize(path)
        if size < max_bytes:
            return

        # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π
        oldest = f"{path}.{backups}"
        if os.path.exists(oldest):
            try:
                os.remove(oldest)
            except Exception:
                pass

        # –°–¥–≤–∏–≥–∞–µ–º
        for i in range(backups - 1, 0, -1):
            src = f"{path}.{i}"
            dst = f"{path}.{i+1}"
            if os.path.exists(src):
                try:
                    os.replace(src, dst)
                except Exception:
                    pass

        # –¢–µ–∫—É—â–∏–π -> .1
        os.replace(path, f"{path}.1")
        logger.info("Rotated %s (size=%d bytes) -> %s.1", path, size, path)
    except Exception as e:
        logger.warning("Rotation failed for %s: %s", path, e)


class JsonStore:
    """–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ JSON —Å –∞—Ç–æ–º–∞—Ä–Ω–æ–π –∑–∞–ø–∏—Å—å—é –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π –ø–æ —Ä–∞–∑–º–µ—Ä—É."""

    def __init__(
        self,
        path: str,
        default: Any,
        rotate_max_bytes: Optional[int] = None,
        rotate_backups: int = 0,
    ):
        self.path = path
        self.default = default
        self.rotate_max_bytes = rotate_max_bytes
        self.rotate_backups = rotate_backups
        self._lock = threading.RLock()
        self.data = self._load()

    def _load(self) -> Any:
        if not os.path.exists(self.path):
            return self.default
        try:
            with open(self.path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.warning("Failed to load %s (%s). Using default.", self.path, e)
            return self.default

    def save(self) -> None:
        with self._lock:
            if self.rotate_max_bytes is not None:
                rotate_file(self.path, self.rotate_max_bytes, self.rotate_backups)
            atomic_write_json(self.path, self.data)

    def get(self) -> Any:
        with self._lock:
            return self.data


# -------------------- TOKEN ESTIMATION --------------------

@dataclass(frozen=True)
class TokenStatus:
    used: int
    left: int


class TokenEstimator:
    """
    –û—Ü–µ–Ω—â–∏–∫ —Ç–æ–∫–µ–Ω–æ–≤:
    - tiktoken cl100k_base –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    - overhead –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    - —Ñ–∏–∫—Å-–æ—Ü–µ–Ω–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """

    def __init__(self) -> None:
        self._enc = None
        if get_encoding is not None:
            try:
                self._enc = get_encoding("cl100k_base")
            except Exception as e:
                logger.warning("tiktoken init failed: %s", e)
                self._enc = None

    def count_text_tokens(self, text: str) -> int:
        if not text:
            return 0
        if self._enc is None:
            # fallback rough
            return max(1, len(text) // 3)
        return len(self._enc.encode(text))

    def truncate_text_to_tokens_keep_tail(self, text: str, max_tokens: int) -> str:
        """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–∫—Å–∏–º—É–º max_tokens, —Å–æ—Ö—Ä–∞–Ω—è—è —Ö–≤–æ—Å—Ç (—Å–∞–º–æ–µ —Å–≤–µ–∂–µ–µ)."""
        if max_tokens <= 0:
            return ""
        if not text:
            return ""
        if self._enc is None:
            # fallback: –ø—Ä–∏–º–µ—Ä–Ω–æ
            max_chars = max(1, max_tokens * 3)
            if len(text) <= max_chars:
                return text
            return "‚Ä¶ " + text[-max_chars:]
        toks = self._enc.encode(text)
        if len(toks) <= max_tokens:
            return text
        cut = toks[-max_tokens:]
        out = self._enc.decode(cut)
        return "‚Ä¶ " + out

    @staticmethod
    def _iter_text_blocks(content: Any) -> List[str]:
        if isinstance(content, str):
            return [content]
        if isinstance(content, list):
            out: List[str] = []
            for b in content:
                if isinstance(b, dict) and b.get("type") == "text" and isinstance(b.get("text"), str):
                    out.append(b["text"])
            return out
        return []

    @staticmethod
    def _count_images(content: Any) -> int:
        if isinstance(content, list):
            n = 0
            for b in content:
                if not isinstance(b, dict):
                    continue
                if b.get("type") in ("image_url", "telegram_photo"):
                    n += 1
            return n
        return 0

    def estimate_messages(self, messages: List[Dict[str, Any]]) -> int:
        total = TOKENS_PRIMING_OVERHEAD
        for m in messages:
            total += TOKENS_PER_MESSAGE_OVERHEAD
            content = m.get("content")
            for part in self._iter_text_blocks(content):
                total += self.count_text_tokens(part)
            total += self._count_images(content) * IMAGE_TOKEN_ESTIMATE
        return total


# -------------------- BOT STATE --------------------

settings_store = JsonStore(SETTINGS_FILE, default={})
history_store = JsonStore(
    HISTORY_FILE,
    default={},
    rotate_max_bytes=HISTORY_ROTATE_MAX_BYTES,
    rotate_backups=HISTORY_ROTATE_BACKUPS,
)

user_settings: Dict[str, Dict[str, Any]] = settings_store.get()
chat_histories: Dict[str, List[Dict[str, Any]]] = history_store.get()

token_estimator = TokenEstimator()

bot = telebot.TeleBot(API_TOKEN)
client = OpenAI(base_url=BASE_URL, api_key=OPENAI_API_KEY)


# -------------------- SETTINGS / PROMPTS --------------------

DEFAULT_CFG = {"role": "default", "temperature": 0.7, "model": "local_default"}


def get_settings(user_id: Union[int, str]) -> Dict[str, Any]:
    k = uid(user_id)
    if k not in user_settings or not isinstance(user_settings.get(k), dict):
        user_settings[k] = DEFAULT_CFG.copy()
        settings_store.save()
    for kk, vv in DEFAULT_CFG.items():
        user_settings[k].setdefault(kk, vv)
    return user_settings[k]


def system_prompt_for(user_id: Union[int, str]) -> str:
    s = get_settings(user_id)
    role_text = ROLES.get(s.get("role", "default"), ROLES["default"])
    return f"{role_text}\n\n{RESPONSE_FORMAT_INSTRUCTION}"


def init_history(user_id: Union[int, str]) -> None:
    k = uid(user_id)
    chat_histories[k] = [{"role": "system", "content": system_prompt_for(k)}]
    history_store.save()


# -------------------- SUMMARY / COMPRESSION --------------------

def _is_summary_msg(msg: Dict[str, Any]) -> bool:
    return msg.get("role") == "system" and isinstance(msg.get("content"), str) and msg["content"].startswith("[SUMMARY]")


def _is_ultra_msg(msg: Dict[str, Any]) -> bool:
    return msg.get("role") == "system" and isinstance(msg.get("content"), str) and msg["content"].startswith("[ULTRA]")


def _content_to_plain_text(msg: Dict[str, Any]) -> str:
    content = msg.get("content")
    if isinstance(content, str):
        return content.strip()
    if isinstance(content, list):
        parts: List[str] = []
        for b in content:
            if not isinstance(b, dict):
                continue
            if b.get("type") == "text" and isinstance(b.get("text"), str):
                parts.append(b["text"])
            elif b.get("type") in ("image_url", "telegram_photo"):
                parts.append("[–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]")
        return " ".join(p.strip() for p in parts if p).strip()
    return ""


def compress_summary(history_slice: List[Dict[str, Any]]) -> str:
    parts: List[str] = []
    for msg in history_slice:
        role = msg.get("role")
        if role not in ("user", "assistant"):
            continue
        text = _content_to_plain_text(msg)
        if not text:
            continue
        parts.append(("U: " if role == "user" else "A: ") + text)
    return " | ".join(parts)


def compression_engine(user_id: Union[int, str]) -> None:
    k = uid(user_id)
    history = chat_histories.get(k)
    if not history:
        init_history(k)
        return

    # Ensure first system prompt exists
    if history[0].get("role") != "system":
        history.insert(0, {"role": "system", "content": system_prompt_for(k)})

    has_sum = any(_is_summary_msg(m) for m in history)
    has_ultra = any(_is_ultra_msg(m) for m in history)

    # Stage 1: add summary once
    if len(history) > 12 and not has_sum and not has_ultra:
        window = history[1:9]
        summary = compress_summary(window)
        history = [history[0], {"role": "system", "content": f"[SUMMARY] {summary}"}] + history[9:]
        chat_histories[k] = history

    # Stage 2: compress summary to ultra
    history = chat_histories[k]
    if len(history) > 18 and not any(_is_ultra_msg(m) for m in history):
        for i, m in enumerate(history):
            if _is_summary_msg(m):
                old = m["content"]
                compact = old.replace("[SUMMARY] ", "")
                if len(compact) > 240:
                    compact = compact[:240].rstrip() + "‚Ä¶"
                history[i] = {"role": "system", "content": f"[ULTRA] {compact}"}
                chat_histories[k] = history
                break

    history_store.save()


# -------------------- STRICT TOKEN BUDGET --------------------

def _extract_summary_msg(history: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
    for m in history[1:]:
        if _is_ultra_msg(m) or _is_summary_msg(m):
            return m
    return None


def _non_system_msgs(history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    return [m for m in history if m.get("role") != "system"]


def _rebuild_history(sys0: Dict[str, Any], summary: Optional[Dict[str, Any]], tail: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    out = [sys0]
    if summary is not None:
        out.append(summary)
    out.extend(tail)
    return out


def enforce_token_budget_strict(user_id: Union[int, str]) -> None:
    """
    –°—Ç—Ä–æ–≥–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∏—Å—Ç–æ—Ä–∏—é –∫ TOKEN_LIMIT (–ø–æ –æ—Ü–µ–Ω–∫–µ).
    1) –û—Å—Ç–∞–≤–ª—è–µ—Ç system + (summary/ultra) + —Ö–≤–æ—Å—Ç –¥–∏–∞–ª–æ–≥–∞.
    2) –ï—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ ‚Äî —É–¥–∞–ª—è–µ—Ç —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Ö–≤–æ—Å—Ç–∞.
    3) –ï—Å–ª–∏ –¥–∞–∂–µ –æ–¥–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ ‚Äî –æ–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç (keep-tail).
    """
    k = uid(user_id)
    history = chat_histories.get(k)
    if not history:
        init_history(k)
        return

    sys0 = history[0] if history and history[0].get("role") == "system" else {"role": "system", "content": system_prompt_for(k)}
    summary = _extract_summary_msg(history)

    tail = _non_system_msgs(history)

    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è—Ç—å —Å—Ç–∞—Ä–æ–µ
    candidate = _rebuild_history(sys0, summary, tail)
    while len(tail) > 1 and token_estimator.estimate_messages(candidate) > TOKEN_LIMIT:
        tail = tail[1:]
        candidate = _rebuild_history(sys0, summary, tail)

    # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –º–Ω–æ–≥–æ –∏ –æ—Å—Ç–∞–ª—Å—è 1 —Ö–≤–æ—Å—Ç–æ–≤–æ–π message: –ø—Ä–æ–±—É–µ–º –æ–±—Ä–µ–∑–∞—Ç—å —Ç–µ–∫—Å—Ç
    if token_estimator.estimate_messages(candidate) > TOKEN_LIMIT and tail:
        last = tail[-1]
        content = last.get("content")

        # –ë–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –∏–∑ content –∏ –æ–±—Ä–µ–∑–∞–µ–º
        def get_joined_text(c: Any) -> Optional[str]:
            if isinstance(c, str):
                return c
            if isinstance(c, list):
                texts = []
                for b in c:
                    if isinstance(b, dict) and b.get("type") == "text" and isinstance(b.get("text"), str):
                        texts.append(b["text"])
                joined = " ".join(t.strip() for t in texts if t and isinstance(t, str)).strip()
                return joined if joined else None
            return None

        joined_text = get_joined_text(content)
        if joined_text:
            # –æ—Ü–µ–Ω–∏–º, —Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤ "—Å—ä–µ–¥–∞–µ—Ç" –≤—Å—ë –∫—Ä–æ–º–µ —Ç–µ–∫—Å—Ç–∞
            last_copy = dict(last)
            if isinstance(content, str):
                last_copy["content"] = ""
            else:
                # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–ª–æ–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –Ω–æ —É–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç
                if isinstance(content, list):
                    kept_blocks = []
                    for b in content:
                        if isinstance(b, dict) and b.get("type") in ("image_url", "telegram_photo"):
                            kept_blocks.append(b)
                        elif isinstance(b, dict) and b.get("type") == "telegram_photo":
                            kept_blocks.append(b)
                    last_copy["content"] = kept_blocks
                else:
                    last_copy["content"] = ""

            base_candidate = _rebuild_history(sys0, summary, tail[:-1] + [last_copy])
            base_tokens = token_estimator.estimate_messages(base_candidate)
            allowance = TOKEN_LIMIT - base_tokens
            allowance = max(0, allowance)

            # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º—É–º, —á—Ç–æ–±—ã —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å
            allowance = max(allowance, MIN_TEXT_TOKENS_TO_KEEP)

            truncated = token_estimator.truncate_text_to_tokens_keep_tail(joined_text, allowance)

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏—Å—Ç–æ—Ä–∏—é (–Ω–µ –ª–æ–º–∞–µ–º —Ñ–æ—Ä–º–∞—Ç telegram_photo)
            if isinstance(content, str):
                last["content"] = truncated
            elif isinstance(content, list):
                new_blocks: List[Dict[str, Any]] = []
                # —Å–æ—Ö—Ä–∞–Ω–∏–º "telegram_photo" –±–ª–æ–∫(–∏), –µ—Å–ª–∏ –µ—Å—Ç—å
                for b in content:
                    if isinstance(b, dict) and b.get("type") == "telegram_photo":
                        # caption —É–±–∏—Ä–∞–µ–º, —Ç–µ–∫—Å—Ç –ø–æ–π–¥–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º –±–ª–æ–∫–æ–º
                        new_b = dict(b)
                        new_b.pop("caption", None)
                        new_blocks.append(new_b)
                new_blocks.append({"type": "text", "text": truncated})
                last["content"] = new_blocks

            tail[-1] = last
            candidate = _rebuild_history(sys0, summary, tail)

    chat_histories[k] = candidate
    history_store.save()


def get_token_status(user_id: Union[int, str]) -> TokenStatus:
    k = uid(user_id)
    history = chat_histories.get(k) or []
    used = token_estimator.estimate_messages(history)
    return TokenStatus(used=used, left=TOKEN_LIMIT - used)


# -------------------- STORAGE FORMAT (NO BASE64 IN JSON) --------------------

def store_user_text(user_id: str, text: str) -> None:
    chat_histories[user_id].append({"role": "user", "content": [{"type": "text", "text": text}]})
    history_store.save()


def store_user_photo(user_id: str, file_id: str, caption: str) -> None:
    chat_histories[user_id].append(
        {"role": "user", "content": [{"type": "telegram_photo", "file_id": file_id, "caption": caption}]}
    )
    history_store.save()


def store_assistant_text(user_id: str, text: str) -> None:
    chat_histories[user_id].append({"role": "assistant", "content": text})
    history_store.save()


def materialize_for_api(history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []

    for msg in history:
        role = msg.get("role")
        content = msg.get("content")

        if isinstance(content, str) or content is None:
            out.append({"role": role, "content": content or ""})
            continue

        if isinstance(content, list):
            blocks: List[Dict[str, Any]] = []
            for b in content:
                if not isinstance(b, dict):
                    continue
                t = b.get("type")

                if t == "text":
                    text = b.get("text")
                    if isinstance(text, str) and text.strip():
                        blocks.append({"type": "text", "text": text})

                elif t == "image_url":
                    blocks.append(b)

                elif t == "telegram_photo":
                    file_id = b.get("file_id")
                    caption = b.get("caption") if isinstance(b.get("caption"), str) else ""
                    if isinstance(file_id, str) and file_id:
                        try:
                            file_info = bot.get_file(file_id)
                            downloaded = bot.download_file(file_info.file_path)
                            b64 = base64.b64encode(downloaded).decode("utf-8")
                            blocks.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})
                        except Exception as e:
                            logger.warning("Failed to materialize image (file_id=%s): %s", file_id, e)
                            blocks.append({"type": "text", "text": "[–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ]"})
                    if caption.strip():
                        blocks.append({"type": "text", "text": caption})

            out.append({"role": role, "content": blocks if blocks else ""})
            continue

        out.append({"role": role, "content": str(content)})

    return out


# -------------------- UI (KEYBOARDS) --------------------

def main_menu_keyboard(user_id: Union[int, str]) -> types.InlineKeyboardMarkup:
    st = get_token_status(user_id)
    s = get_settings(user_id)

    markup = types.InlineKeyboardMarkup(row_width=2)
    markup.add(types.InlineKeyboardButton(f"üß† Tokens: {st.used}/{TOKEN_LIMIT}", callback_data="show_tokens"))
    markup.add(types.InlineKeyboardButton("üóëÔ∏è –ù–æ–≤—ã–π —á–∞—Ç", callback_data="new_chat"))
    markup.add(types.InlineKeyboardButton(f"üé≠ –†–æ–ª—å: {s['role']}", callback_data="menu_roles"))
    markup.add(types.InlineKeyboardButton(f"ü§ñ –ú–æ–¥–µ–ª—å: {s['model']}", callback_data="menu_models"))
    markup.add(types.InlineKeyboardButton(f"üå°Ô∏è Temp: {s['temperature']}", callback_data="menu_temp"))
    return markup


def roles_keyboard(user_id: Union[int, str]) -> types.InlineKeyboardMarkup:
    current = get_settings(user_id)["role"]
    markup = types.InlineKeyboardMarkup()
    for r in ROLES.keys():
        mark = " ‚úÖ" if r == current else ""
        markup.add(types.InlineKeyboardButton(f"üé≠ {r}{mark}", callback_data=f"set_role_{r}"))
    markup.add(types.InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="main_menu"))
    return markup


def models_keyboard(user_id: Union[int, str]) -> types.InlineKeyboardMarkup:
    current = get_settings(user_id)["model"]
    markup = types.InlineKeyboardMarkup()
    for m in AVAILABLE_MODELS.keys():
        mark = " ‚úÖ" if m == current else ""
        markup.add(types.InlineKeyboardButton(f"ü§ñ {m}{mark}", callback_data=f"set_model_{m}"))
    markup.add(types.InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="main_menu"))
    return markup


def temp_keyboard(user_id: Union[int, str]) -> types.InlineKeyboardMarkup:
    current = float(get_settings(user_id)["temperature"])
    markup = types.InlineKeyboardMarkup()
    for t in ["0.1", "0.3", "0.7", "1.0"]:
        mark = " ‚úÖ" if float(t) == current else ""
        markup.add(types.InlineKeyboardButton(f"üå°Ô∏è {t}{mark}", callback_data=f"set_temp_{t}"))
    markup.add(types.InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="main_menu"))
    return markup


# -------------------- TELEGRAM UTILS --------------------

def safe_delete(chat_id: int, message_id: int) -> None:
    try:
        bot.delete_message(chat_id, message_id)
    except Exception:
        pass


def safe_edit_text(chat_id: int, message_id: int, text: str, reply_markup: Optional[Any] = None) -> None:
    try:
        bot.edit_message_text(text, chat_id, message_id, reply_markup=reply_markup)
    except Exception:
        try:
            bot.send_message(chat_id, text, reply_markup=reply_markup)
        except Exception:
            pass


def send_long_message(chat_id: int, text: str, reply_markup: Optional[Any] = None) -> None:
    max_len = 3900
    chunks = [text[i:i + max_len] for i in range(0, len(text), max_len)] or [""]
    for i, chunk in enumerate(chunks):
        bot.send_message(chat_id, chunk, reply_markup=reply_markup if i == len(chunks) - 1 else None)


# -------------------- COMMANDS --------------------

@bot.message_handler(commands=["start"])
def cmd_start(message: types.Message) -> None:
    user_id = uid(message.from_user.id)
    init_history(user_id)
    bot.reply_to(message, "‚öôÔ∏è –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è:", reply_markup=main_menu_keyboard(user_id))


@bot.message_handler(commands=["export"])
def cmd_export(message: types.Message) -> None:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ JSON –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª–æ–º.
    """
    user_id = uid(message.from_user.id)
    if user_id not in chat_histories:
        init_history(user_id)

    # –ø–µ—Ä–µ–¥ —ç–∫—Å–ø–æ—Ä—Ç–æ–º –ø—Ä–∏–≤–æ–¥–∏–º –∏—Å—Ç–æ—Ä–∏—é –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É
    compression_engine(user_id)
    enforce_token_budget_strict(user_id)

    payload = {
        "user_id": user_id,
        "settings": get_settings(user_id),
        "token_status_estimate": {
            "used": get_token_status(user_id).used,
            "left": get_token_status(user_id).left,
            "limit": TOKEN_LIMIT,
        },
        "history": chat_histories.get(user_id, []),
    }

    data = json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8")
    bio = io.BytesIO(data)
    bio.name = f"export_{user_id}.json"  # telebot –∏—Å–ø–æ–ª—å–∑—É–µ—Ç name –∫–∞–∫ filename

    bot.send_document(
        message.chat.id,
        bio,
        caption="üì¶ –≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (JSON).",
    )


# -------------------- CALLBACKS --------------------

@bot.callback_query_handler(func=lambda call: True)
def callback_handler(call: types.CallbackQuery) -> None:
    user_id = uid(call.from_user.id)
    s = get_settings(user_id)

    if call.data == "main_menu":
        safe_edit_text(call.message.chat.id, call.message.message_id, "‚öôÔ∏è –ú–µ–Ω—é:", reply_markup=main_menu_keyboard(user_id))

    elif call.data == "new_chat":
        init_history(user_id)
        bot.send_message(call.message.chat.id, "üßπ –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞.", reply_markup=main_menu_keyboard(user_id))

    elif call.data == "menu_models":
        safe_edit_text(call.message.chat.id, call.message.message_id, "ü§ñ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", reply_markup=models_keyboard(user_id))

    elif call.data.startswith("set_model_"):
        s["model"] = call.data.replace("set_model_", "", 1)
        settings_store.save()
        safe_edit_text(call.message.chat.id, call.message.message_id, "‚úÖ –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.", reply_markup=main_menu_keyboard(user_id))

    elif call.data == "menu_roles":
        safe_edit_text(call.message.chat.id, call.message.message_id, "üé≠ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–ª—å:", reply_markup=roles_keyboard(user_id))

    elif call.data.startswith("set_role_"):
        s["role"] = call.data.replace("set_role_", "", 1)
        settings_store.save()
        init_history(user_id)
        safe_edit_text(call.message.chat.id, call.message.message_id, "‚úÖ –†–æ–ª—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∞.", reply_markup=main_menu_keyboard(user_id))

    elif call.data == "menu_temp":
        safe_edit_text(call.message.chat.id, call.message.message_id, "üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:", reply_markup=temp_keyboard(user_id))

    elif call.data.startswith("set_temp_"):
        try:
            s["temperature"] = float(call.data.replace("set_temp_", "", 1))
        except ValueError:
            s["temperature"] = DEFAULT_CFG["temperature"]
        settings_store.save()
        safe_edit_text(call.message.chat.id, call.message.message_id, "‚úÖ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞.", reply_markup=main_menu_keyboard(user_id))

    elif call.data == "show_tokens":
        compression_engine(user_id)
        enforce_token_budget_strict(user_id)
        st = get_token_status(user_id)
        bot.send_message(
            call.message.chat.id,
            f"üß† Tokens (–æ—Ü–µ–Ω–∫–∞): {st.used}/{TOKEN_LIMIT}\n"
            f"üìâ –û—Å—Ç–∞–ª–æ—Å—å (–æ—Ü–µ–Ω–∫–∞): {st.left}\n\n"
            f"üì¶ –≠–∫—Å–ø–æ—Ä—Ç: /export",
            reply_markup=main_menu_keyboard(user_id),
        )


# -------------------- MAIN MESSAGE HANDLER --------------------

@bot.message_handler(content_types=["text", "photo"])
def handle_message(message: types.Message) -> None:
    user_id = uid(message.from_user.id)
    if user_id not in chat_histories:
        init_history(user_id)

    s = get_settings(user_id)

    # –ö–æ–º–ø—Ä–µ—Å—Å–∏—è + —Å—Ç—Ä–æ–≥–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º –î–û –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    compression_engine(user_id)
    enforce_token_budget_strict(user_id)

    model_api = AVAILABLE_MODELS.get(s["model"], AVAILABLE_MODELS["local_default"])
    loading = bot.reply_to(message, "‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–±–µ–∑ base64 –≤ JSON)
        if message.content_type == "photo" and message.photo:
            file_id = message.photo[-1].file_id
            caption = (message.caption or "–û–ø–∏—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ").strip()
            store_user_photo(user_id, file_id=file_id, caption=caption)
        else:
            text = (message.text or "").strip()
            if not text:
                safe_delete(message.chat.id, loading.message_id)
                bot.send_message(message.chat.id, "–ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.", reply_markup=main_menu_keyboard(user_id))
                return
            store_user_text(user_id, text=text)

        # –°–Ω–æ–≤–∞ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –ª–∏–º–∏—Ç—É (—Ç–µ–ø–µ—Ä—å —É–∂–µ —Å –Ω–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º)
        compression_engine(user_id)
        enforce_token_budget_strict(user_id)

        # –ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑—É–µ–º —Ñ–æ—Ç–æ -> base64 —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        api_messages = materialize_for_api(chat_histories[user_id])

        completion = client.chat.completions.create(
            model=model_api,
            messages=api_messages,
            temperature=float(s["temperature"]),
        )

        response = completion.choices[0].message.content or ""
        if "–û–¢–í–ï–¢:" in response:
            response = response.split("–û–¢–í–ï–¢:", 1)[1].strip()

        safe_delete(message.chat.id, loading.message_id)
        send_long_message(message.chat.id, response, reply_markup=main_menu_keyboard(user_id))

        store_assistant_text(user_id, response)

        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî —Å–Ω–æ–≤–∞ –ª–∏–º–∏—Ç, —á—Ç–æ–±—ã JSON –Ω–µ —Ä–∞—Å–ø—É—Ö–∞–ª
        compression_engine(user_id)
        enforce_token_budget_strict(user_id)

    except Exception as e:
        safe_delete(message.chat.id, loading.message_id)
        logger.exception("Error while handling message: %s", e)
        bot.send_message(message.chat.id, f"–û—à–∏–±–∫–∞: {e}", reply_markup=main_menu_keyboard(user_id))


if __name__ == "__main__":
    logger.info("BOT READY ‚úî")
    bot.polling(non_stop=True)